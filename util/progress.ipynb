{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_CO_vector(df_all: pd.DataFrame,\n",
    "                    sample_feature_cols: list,\n",
    "                    t_list=None,\n",
    "                    n_seeds: int = 100,\n",
    "                    test_size: float = 0.2,\n",
    "                    config_path: str = \"config.json\",\n",
    "                    base_cls_params: dict = None):\n",
    "    \"\"\"\n",
    "    每個 seed：\n",
    "      - 9 個分類器：只把「驗證集」機率寫入 outputs_val_only（train 不寫）\n",
    "      - 最後：對每個 cell，若有驗證值就取平均，否則保持 NaN\n",
    "\n",
    "    參數\n",
    "    ----\n",
    "    df_all : 包含至少 ['time','event'] + sample_feature_cols 的 DataFrame\n",
    "    sample_feature_cols : 特徵欄位清單\n",
    "    t_list : 要跑的時間閾值清單；若為 None，預設使用 config.json 內 CO_params 的 key（排序後）\n",
    "    n_seeds : 重複次數（不同 random_state）\n",
    "    test_size : 驗證集比例\n",
    "    config_path : config.json 路徑（需包含 {\"CO_params\": {...}}）\n",
    "    base_cls_params : 給 XGBClassifier 的共用基礎參數（可覆蓋預設值）\n",
    "                      預設為:\n",
    "                        {\n",
    "                          \"objective\": \"binary:logistic\",\n",
    "                          \"eval_metric\": \"logloss\",\n",
    "                          \"tree_method\": \"hist\",\n",
    "                          \"verbosity\": 0,\n",
    "                          \"device\": \"cuda\"\n",
    "                        }\n",
    "                      若無 GPU 可改成 device=\"cpu\"\n",
    "    回傳\n",
    "    ----\n",
    "    final : DataFrame，index 與 df_all 對齊，欄位為 [f\"T={t}\" for t in t_list]，\n",
    "            值為 OOF（驗證集）機率的多次平均；若從未被抽中驗證集則為 NaN。\n",
    "    \"\"\"\n",
    "\n",
    "    # 讀 config.json 並取出 CO_params\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        _cfg = json.load(f)\n",
    "\n",
    "    if \"CO_params\" not in _cfg:\n",
    "        raise KeyError(f\"`CO_params` not found in {config_path}\")\n",
    "\n",
    "    # 將 key 轉成 float 方便用數值比較/排序\n",
    "    CO_params = {float(k): v for k, v in _cfg[\"CO_params\"].items()}\n",
    "\n",
    "    # 若沒給 t_list，就用 config 裡的 key（排序）\n",
    "    if t_list is None:\n",
    "        t_list = sorted(CO_params.keys())\n",
    "\n",
    "    cols_9T = [f\"T={t}\" for t in t_list]\n",
    "\n",
    "    # 預設的 XGBClassifier 基礎參數\n",
    "    default_base = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"verbosity\": 0,\n",
    "        \"device\": \"cuda\"   # 沒 GPU 的話改成 \"cpu\"\n",
    "    }\n",
    "    if base_cls_params is not None:\n",
    "        default_base.update(base_cls_params)\n",
    "\n",
    "    # 全局累積器：只累計驗證集格子\n",
    "    val_sum = pd.DataFrame(0.0, index=df_all.index, columns=cols_9T)\n",
    "    val_cnt = pd.DataFrame(0,   index=df_all.index, columns=cols_9T, dtype=int)\n",
    "\n",
    "    for seed in tqdm(range(n_seeds), desc=\"Seeds\"):\n",
    "        # 這份只放「驗證集」的機率\n",
    "        outputs_val_only = pd.DataFrame(np.nan, index=df_all.index, columns=cols_9T, dtype=float)\n",
    "\n",
    "        # === 逐 T 訓練二分類器 ===\n",
    "        for j, T in enumerate(t_list):\n",
    "            col = cols_9T[j]\n",
    "\n",
    "            # 排除 (time <= T & event==0)\n",
    "            mask_keep = ~((df_all[\"time\"] <= T) & (df_all[\"event\"] == 0))\n",
    "            valid = df_all[mask_keep].copy()\n",
    "\n",
    "            # label\n",
    "            valid[\"label\"] = (valid[\"time\"] >= T).astype(int)\n",
    "            X_all = valid[sample_feature_cols]\n",
    "            y_all = valid[\"label\"].astype(int)\n",
    "            idx_all = valid.index\n",
    "\n",
    "            X_tr, X_va, y_tr, y_va, idx_tr, idx_va = train_test_split(\n",
    "                X_all, y_all, idx_all, test_size=test_size, random_state=seed, stratify=y_all\n",
    "            )\n",
    "\n",
    "            # 合併：基礎參數 + 該 T 的超參數\n",
    "            if T not in CO_params:\n",
    "                raise KeyError(f\"T={T} not found in CO_params loaded from {config_path}\")\n",
    "            this_params = default_base.copy()\n",
    "            this_params.update(CO_params[T])\n",
    "\n",
    "            clf = xgb.XGBClassifier(**this_params)\n",
    "            clf.fit(X_tr, y_tr)\n",
    "\n",
    "            prob_va = clf.predict_proba(X_va)[:, 1]\n",
    "\n",
    "            # 只把驗證集寫入最終平均用矩陣（train 保持 NaN）\n",
    "            outputs_val_only.loc[idx_va, col] = prob_va\n",
    "\n",
    "        # === 累積：只累計驗證值 ===\n",
    "        val_mask = outputs_val_only.notna()\n",
    "        val_sum[val_mask] += outputs_val_only[val_mask]\n",
    "        val_cnt[val_mask] += 1\n",
    "\n",
    "    # === 匯總：僅使用驗證平均，無驗證就留 NaN ===\n",
    "    final = pd.DataFrame(np.nan, index=df_all.index, columns=cols_9T, dtype=float)\n",
    "    has_val = (val_cnt.values > 0)\n",
    "    final.values[has_val] = (val_sum.values[has_val] / np.maximum(val_cnt.values[has_val], 1))\n",
    "\n",
    "    return final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
